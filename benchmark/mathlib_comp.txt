
    fs = [
        files[name]
        for name in files.keys()
        if type(files[name]) == AnnotatedFile
    ]
    fs = fs[:math.floor(len(fs) * 0.8)] #train/test split
    thms = [
        thm
        for f in fs
        for thm in f.theorems
        if type(f) == AnnotatedFile
        and no_errors([thm])
        and type(thm) == AnnotatedTheorem
        and len(thm.proof) > 5
        and len(thm.proof) < 30
        and ("lemma" in thm.decl or "example" in thm.decl or "theorem" in thm.decl)
    ]

    unique_thms = []
    seen_decls = set()
    for thm in thms:
        trim_decl = (
            thm.decl.replace("theorem ", "")
            .replace("lemma ", "")
            .replace("example ", "")
            .replace("problem ", "")
        ).strip()
        if trim_decl not in seen_decls:
            unique_thms.append(thm)
            seen_decls.add(trim_decl)
    thms = unique_thms
    thms = sorted(thms, key=lambda x: len(x.proof))

    print(f"Benchmarking {len(thms)} theorems")

    data = []
    traj = []
    errors = []

    workers = 3
    grouped_thms = []
    current_group = []
    for i, thm in enumerate(thms):
        current_group.append(thm)
        if len(current_group) == workers:
            grouped_thms.append(current_group)
            current_group = []
    if current_group:
        grouped_thms.append(current_group)

    for group in grouped_thms[17:]:
        d, t = process_instancesP(
            [(thm, method) for thm in group for method in methods],
            max_workers=workers,
            output_trajectories=True,
        )

        data.extend(d)
        traj.extend(t)
        save_to_csv(data, "benchmark/data/training/mathlib/computability/data2.csv")
        save_to_csv(traj, "benchmark/data/training/mathlib/computability/traj2.csv")


#for cat theory: 
(first 12, sorted by num thms)